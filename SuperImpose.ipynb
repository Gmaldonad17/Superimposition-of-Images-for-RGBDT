{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1911100c-a8f8-42d4-bbd5-a7bed7f1c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Comment Legend ######\n",
    "\n",
    "    # Describing a function\n",
    "    ### Describing an issue\n",
    "    ###### Infomational ######\n",
    "\n",
    "###### To Do List ######\n",
    "\n",
    "    # Create a function to save bad images for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f321e1-e5e6-434b-87ed-82f74bf65ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmald\\anaconda3\\envs\\senior\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import mmcv\n",
    "import torch\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%run utils/superimposition/functions.ipynb\n",
    "# %run utils/extraction/objClass.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e261f5-e630-4afe-b61a-784a0a1ff563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-12-01_18-03-33', '2022-12-02_13-05-04', '2023-01-24_15-28-00', '2023-01-28_15-50-17', '2023-04-18_16-00-58', '2023-04-18_16-08-43', '2023-04-18_16-24-54', '2023-04-27_12-30-56', '2023-04-27_12-35-33', 'combined_outisde_13.gif', 'newStereo', 'outside_test', 'SII'] \n",
      "Selected File: 2023-01-28_15-50-17\n"
     ]
    }
   ],
   "source": [
    "class Configuration:\n",
    "    def __init__(self, minimal_img, main_img, seg_net, video_format, fps, file_name, skip_frames):\n",
    "        self.minimal_img = minimal_img\n",
    "        self.main_img = main_img\n",
    "        self.seg_net = seg_net\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*video_format)\n",
    "        self.fps = fps\n",
    "        self.main_path = f\"videos/{file_name}/\"\n",
    "        self.processed_path = self.main_path + \"processed/\"\n",
    "        self.skip_frames = skip_frames\n",
    "\n",
    "# List available video files\n",
    "file_list = os.listdir(\"videos\")\n",
    "selected_file = file_list[3]\n",
    "\n",
    "print(file_list, \"\\nSelected File:\", selected_file)\n",
    "\n",
    "# Create a configuration object\n",
    "config = Configuration(minimal_img=\"Thermal\", main_img=\"RGB\", seg_net=\"utils/segmentation/yolov8n-seg.pt\", video_format=\"mp4v\", fps=10, file_name=selected_file, skip_frames=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48e019b-2451-47e0-8196-f8d9759d67e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Ended. Saving videos...\n",
      "Saving complete!\n"
     ]
    }
   ],
   "source": [
    "# Video Processor\n",
    "\n",
    "# Load the segmentation model\n",
    "seg_model = YOLO(config.seg_net)\n",
    "\n",
    "# Open video files\n",
    "rgb_video = cv2.VideoCapture(f\"{config.main_path}rgbout.mp4\")\n",
    "thermal_video = cv2.VideoCapture(f\"{config.main_path}thermalout.mp4\")\n",
    "depth_video = cv2.VideoCapture(f\"{config.main_path}stereoout.mp4\")\n",
    "left_video = cv2.VideoCapture(f\"{config.main_path}leftout.mp4\")\n",
    "\n",
    "# Initialize frame counters\n",
    "calibration_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "# Set the initial frame position for each video\n",
    "rgb_video.set(cv2.CAP_PROP_POS_FRAMES, config.skip_frames)\n",
    "thermal_video.set(cv2.CAP_PROP_POS_FRAMES, config.skip_frames)\n",
    "depth_video.set(cv2.CAP_PROP_POS_FRAMES, config.skip_frames)\n",
    "left_video.set(cv2.CAP_PROP_POS_FRAMES, config.skip_frames)\n",
    "\n",
    "ten_scales = [[1, 1, 1]]\n",
    "ten_offsets = [[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]\n",
    "\n",
    "images = {\"RGB\": None, \"Thermal\": None, \"Left\": None, \"Depth\": None}\n",
    "\n",
    "# Main loop to process video frames\n",
    "while True:\n",
    "    # Read a frame from each video\n",
    "    ret, images[\"RGB\"] = rgb_video.read()\n",
    "    ret1, images[\"Thermal\"] = thermal_video.read()\n",
    "    ret2, images[\"Depth\"] = depth_video.read()\n",
    "    ret3, images[\"Left\"] = left_video.read()\n",
    "    if not (ret & ret1 & ret2 & ret3):\n",
    "        break\n",
    "    \n",
    "    depth_sp = images[\"Depth\"].shape\n",
    "    # Stretch depth to deal with distortion  \n",
    "    images[\"Depth\"] = cv2.resize(images[\"Depth\"], (int(depth_sp[1]*1.2), depth_sp[0]))\n",
    "\n",
    "    # Perform calibration every 2 frames\n",
    "    if calibration_count % 20 == 0:\n",
    "        scales, offset = calibrate_images(images.copy(), seg_model, config.minimal_img, depth_bias=0.85) # 0.85)\n",
    "\n",
    "        if scales is not None and offset is not None:\n",
    "            if ten_scales[0] == [1, 1, 1]:\n",
    "                del ten_scales[0]\n",
    "                del ten_offsets[0]\n",
    "\n",
    "            ten_scales.append(scales)\n",
    "            ten_offsets.append(offset)\n",
    "\n",
    "        if len(ten_scales) > 30:\n",
    "            random_delete = int(np.random.rand() * 30)\n",
    "            \n",
    "            del ten_scales[random_delete]\n",
    "            del ten_offsets[random_delete]\n",
    "\n",
    "        scales, offset = filter_offsets_scales(ten_scales, ten_offsets)\n",
    "        scales = {\"RGB\": scales[0], \"Thermal\": scales[1], \"Depth\": scales[2]}\n",
    "        offset = {\"RGB\": offset[0], \"Thermal\": offset[1], \"Depth\": offset[2]}\n",
    "        offset[\"Depth\"][2] += 15\n",
    "        \n",
    "        # If manual Input is needed add here\n",
    "        # scales = {'RGB': 0.3300825220683977, 'Thermal': 1.0, 'Depth': 1.0634868466154548}\n",
    "        # offset = {'RGB': [53, 102, 83, 72], 'Thermal': [0, 0, 0, 0], 'Depth': [16, 72, 50, 51]}\n",
    "\n",
    "    # Convert stereo frame to grayscale for visualization\n",
    "    images[\"Depth\"] = cv2.cvtColor(images[\"Depth\"], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Modify images based on calibration settings\n",
    "    images[\"Unrelated\"] = superimpose_images(images.copy(), add_color=True)\n",
    "    images = modify_images(images.copy(), scales, offset, images[config.minimal_img].shape[0])\n",
    "\n",
    "    images[\"Related\"] = superimpose_images(images.copy(), add_color=True)\n",
    "\n",
    "    stereo_frame_mapped = cv2.normalize(images[\"Depth\"], None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\n",
    "    stereo_frame_mapped = cv2.equalizeHist(stereo_frame_mapped)\n",
    "    stereo_frame_mapped = cv2.applyColorMap(stereo_frame_mapped, cv2.COLORMAP_JET)\n",
    "    images[\"Color_Depth\"] = stereo_frame_mapped\n",
    "\n",
    "    # Create video files for processed output\n",
    "    if calibration_count == 0:\n",
    "        thermal_out = cv2.VideoWriter(f\"{config.processed_path}Thermal_sii.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "        stereo_out = cv2.VideoWriter(f\"{config.processed_path}Depth_sii.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]), 0) # For GrayScale\n",
    "        stereo_color_out = cv2.VideoWriter(f\"{config.processed_path}Depth_color_sii.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1])) # For GrayScale\n",
    "        rgb_out = cv2.VideoWriter(f\"{config.processed_path}RGB_sii.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "        related_sii_out = cv2.VideoWriter(f\"{config.processed_path}Related_SII.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "        unrelated_sii_out = cv2.VideoWriter(f\"{config.processed_path}Unrelated_SII.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "\n",
    "    # Resize related and unrelated images\n",
    "    images[\"Related\"] = cv2.resize(images[\"Related\"], images[config.minimal_img].shape[:2][::-1])\n",
    "    images[\"Unrelated\"] = cv2.resize(images[\"Unrelated\"], images[config.minimal_img].shape[:2][::-1])\n",
    "\n",
    "    # Display images\n",
    "    for label in images:\n",
    "        cv2.imshow(label, images[label])\n",
    "\n",
    "    # Write frames to output video files\n",
    "    thermal_out.write(images[\"Thermal\"])\n",
    "    stereo_out.write(images[\"Depth\"])\n",
    "    stereo_color_out.write(images[\"Color_Depth\"])\n",
    "    rgb_out.write(images[\"RGB\"])\n",
    "    related_sii_out.write(images[\"Related\"])\n",
    "    unrelated_sii_out.write(images[\"Unrelated\"])\n",
    "\n",
    "    # Increment frame counters\n",
    "    calibration_count += 1\n",
    "    frame_count += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "print(\"\\nProcessing Ended. Saving videos...\")\n",
    "        \n",
    "# Release video files\n",
    "rgb_out.release()\n",
    "thermal_out.release()\n",
    "stereo_out.release()\n",
    "stereo_color_out.release()\n",
    "related_sii_out.release()\n",
    "unrelated_sii_out.release()\n",
    "\n",
    "print(\"Saving complete!\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694bc17-0ac6-437b-9e82-0c3008424a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there was some kind of issue you should be able to recover videos\n",
    "rgb_out.release()\n",
    "thermal_out.release()\n",
    "stereo_out.release()\n",
    "related_sii_out.release()\n",
    "unrelated_sii_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ceb72598-132b-4e7f-98b5-55deefa29be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RGB': 0.3300825220683977, 'Thermal': 1.0, 'Depth': 1.0634868466154548} {'RGB': [53, 102, 83, 72], 'Thermal': [0, 0, 0, 0], 'Depth': [16, 72, 50, 51]}\n"
     ]
    }
   ],
   "source": [
    "print(scales, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9e74a-4901-4962-8b15-b4c4da542c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
