{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cdea58e-7414-4cff-969a-492e922f010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### This program is used to run all the cameras at the sametime at the same framerate ######\n",
    "# https://docs.luxonis.com/en/latest/pages/faq/\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Creates a pipeline for extracting infomation from the Stereo Camera\n",
    "def createNewPipeline(rgb=True, left=True, right=True, stereo=True):\n",
    "    \n",
    "    # Creates pipeline from dai API\n",
    "    pipeline = dai.Pipeline()\n",
    "    \n",
    "    # If an rgb camera is in use then set it up\n",
    "    if rgb:\n",
    "        # Create RGB cam pipline\n",
    "        camRgb = pipeline.create(dai.node.ColorCamera)\n",
    "        \n",
    "        # Set the correct socket to communicate with the pipeline and set resolution\n",
    "        camRgb.setBoardSocket(dai.CameraBoardSocket.RGB)\n",
    "        camRgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "        # camRgb.setVideoSize(1920, 1080)\n",
    "        \n",
    "        # Link pipeline to output node\n",
    "        xoutRgb = pipeline.create(dai.node.XLinkOut)\n",
    "        xoutRgb.setStreamName(\"rgb\")\n",
    "        camRgb.video.link(xoutRgb.input)\n",
    "\n",
    "    if left:\n",
    "        monoLeft = pipeline.create(dai.node.MonoCamera)\n",
    "\n",
    "        monoLeft.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "        monoLeft.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "\n",
    "        xoutLeft = pipeline.create(dai.node.XLinkOut)\n",
    "        xoutLeft.setStreamName(\"left\")\n",
    "        monoLeft.out.link(xoutLeft.input)\n",
    "\n",
    "    if right:\n",
    "        monoRight = pipeline.create(dai.node.MonoCamera)\n",
    "\n",
    "        monoRight.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "        monoRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "        xoutRight = pipeline.create(dai.node.XLinkOut)\n",
    "        xoutRight.setStreamName(\"right\")\n",
    "        monoRight.out.link(xoutRight.input)\n",
    "        \n",
    "    if stereo:\n",
    "        # Create a pipeline for developing the stereo depth\n",
    "        stereo = pipeline.create(dai.node.StereoDepth)\n",
    "        \n",
    "        # Create configuration \n",
    "        stereo.initialConfig.setConfidenceThreshold(255)\n",
    "        stereo.setLeftRightCheck(True)\n",
    "        stereo.setSubpixel(False)\n",
    "        \n",
    "        monoLeft.out.link(stereo.left)\n",
    "        monoRight.out.link(stereo.right)\n",
    "        \n",
    "        xoutDepth = pipeline.create(dai.node.XLinkOut)\n",
    "        xoutDepth.setStreamName(\"depth\")\n",
    "        stereo.depth.link(xoutDepth.input)\n",
    "\n",
    "    device = dai.Device(pipeline)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    if rgb:\n",
    "        rgbVideo = device.getOutputQueue(name=\"rgb\", maxSize=1, blocking=False)\n",
    "        output.append(rgbVideo)\n",
    "\n",
    "    if left:\n",
    "        leftVideo = device.getOutputQueue(name=\"left\", maxSize=1, blocking=False)\n",
    "        output.append(leftVideo)\n",
    "\n",
    "    if right:\n",
    "        rightVideo = device.getOutputQueue(name=\"right\", maxSize=1, blocking=False)\n",
    "        output.append(rightVideo)\n",
    "        \n",
    "    if stereo:\n",
    "        # dispQ = device.getOutputQueue(name=\"disp\", maxSize=1, blocking=False)\n",
    "        depthQueue = device.getOutputQueue(name=\"depth\", maxSize=1, blocking=False)\n",
    "        output.append(depthQueue)\n",
    "        output.append(stereo)\n",
    "\n",
    "    output.append(device)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b392e7e-7298-4d4f-841e-ace5748fe649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgbFrame: (1080, 1920, 3)\n",
      "leftFrame: (400, 640)\n",
      "rightFrame: (400, 640)\n",
      "Thermalframe: (512, 640, 3)\n",
      "stereoFrame: (400, 640)\n",
      "2022-12-08_12-49-00\n",
      "640 400\n",
      "0:00:17.650750\n"
     ]
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "\n",
    "RECORD = True\n",
    "\n",
    "output = createNewPipeline()\n",
    "\n",
    "rgbCam = output[0]\n",
    "leftCam = output[1]\n",
    "rightCam = output[2]\n",
    "thermalCam = cv2.VideoCapture(0)\n",
    "stereoCam = output[3]\n",
    "\n",
    "stereo = output[4]\n",
    "\n",
    "rgbFrame = rgbCam.get().getCvFrame()\n",
    "leftFrame = leftCam.get().getCvFrame()\n",
    "rightFrame = rightCam.get().getCvFrame()\n",
    "ret, Thermalframe = thermalCam.read()\n",
    "stereoFrame = stereoCam.get().getCvFrame()\n",
    "\n",
    "print(\"rgbFrame:\", rgbFrame.shape)\n",
    "print(\"leftFrame:\", leftFrame.shape)\n",
    "print(\"rightFrame:\", rightFrame.shape)\n",
    "print(\"Thermalframe:\", Thermalframe.shape)\n",
    "print(\"stereoFrame:\", stereoFrame.shape)\n",
    "\n",
    "FPS = 10\n",
    "timeNow = str(datetime.now())[:-7].replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "print(timeNow)\n",
    "\n",
    "if RECORD:\n",
    "    base = f\"videos/{timeNow}\"\n",
    "    os.mkdir(base)\n",
    "    os.mkdir(f\"{base}/processed\")\n",
    "\n",
    "    rgbout = cv2.VideoWriter(f\"{base}/rgbout.mp4\", fourcc, FPS, (rgbFrame.shape[1], rgbFrame.shape[0]))\n",
    "    leftout = cv2.VideoWriter(f\"{base}/leftout.mp4\", fourcc, FPS, (leftFrame.shape[1], leftFrame.shape[0]), 0)\n",
    "    rightout = cv2.VideoWriter(f\"{base}/rightout.mp4\", fourcc, FPS, (rightFrame.shape[1], rightFrame.shape[0]), 0)\n",
    "    thermalout = cv2.VideoWriter(f\"{base}/thermalout.mp4\", fourcc, FPS, (Thermalframe.shape[1], Thermalframe.shape[0]), 0)\n",
    "    stereoout = cv2.VideoWriter(f\"{base}/stereoout.mp4\", fourcc, FPS, (stereoFrame.shape[1], stereoFrame.shape[0]), 0)\n",
    "\n",
    "print(stereoFrame.shape[1], stereoFrame.shape[0])\n",
    "\n",
    "#time.sleep(7)\n",
    "t0 = datetime.now()\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # Determine the initial frame time \n",
    "    initialFrameTime = datetime.now()\n",
    "          \n",
    "    rgbFrame = rgbCam.get().getCvFrame()\n",
    "    leftFrame = leftCam.get().getCvFrame()\n",
    "    rightFrame = rightCam.get().getCvFrame()\n",
    "    ret, Thermalframe = thermalCam.read()\n",
    "    stereoFrame = stereoCam.get().getFrame()\n",
    "    \n",
    "    \n",
    "    Thermalframe = cv2.cvtColor(Thermalframe, cv2.COLOR_BGR2GRAY)\n",
    "    stereoFrame[0:5,0:5] = 30000 # MAX\n",
    "    stereoFrame = cv2.normalize(stereoFrame, None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\n",
    "    # stereoFrame = cv2.equalizeHist(stereoFrame)\n",
    "    # stereoFrame = cv2.applyColorMap(stereoFrame, cv2.COLORMAP_JET)\n",
    "    \n",
    "    if RECORD:\n",
    "        rgbout.write(rgbFrame)\n",
    "        leftout.write(leftFrame)\n",
    "        rightout.write(rightFrame)\n",
    "        thermalout.write(Thermalframe)\n",
    "        stereoout.write(stereoFrame)\n",
    "    \n",
    "    rgbFrame = cv2.resize(rgbFrame, (960, 540))\n",
    "    cv2.imshow('rgbFrame', rgbFrame)\n",
    "    cv2.imshow('leftFrame', leftFrame)\n",
    "    cv2.imshow('rightFrame', rightFrame)\n",
    "    cv2.imshow('thermalCam', Thermalframe)\n",
    "    cv2.imshow('stereoFrame', stereoFrame)\n",
    "    \n",
    "    lateFrameDifference = float( str(datetime.now() - initialFrameTime)[7:] )\n",
    "    \n",
    "    while (lateFrameDifference < (1/FPS)):\n",
    "        lateFrameDifference = float( str(datetime.now() - initialFrameTime)[7:] )\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "        \n",
    "t1 = datetime.now()\n",
    "\n",
    "if RECORD:\n",
    "    rgbout.release()\n",
    "    leftout.release()\n",
    "    rightout.release()\n",
    "    thermalout.release()\n",
    "    stereoout.release()\n",
    "    thermalCam.release()\n",
    "\n",
    "print(t1 - t0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f2deb-0ec2-4523-b5e5-7d8f391a217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%run utils/superimposition/functions.ipynb\n",
    "%run utils/extraction/objClass.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0accde8-4f9b-46a2-979e-53dd038f8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "\n",
    "RECORD = True\n",
    "\n",
    "output = createNewPipeline()\n",
    "\n",
    "rgbCam = output[0]\n",
    "leftCam = output[1]\n",
    "rightCam = output[2]\n",
    "thermalCam = cv2.VideoCapture(0)\n",
    "stereoCam = output[3]\n",
    "\n",
    "stereo = output[4]\n",
    "\n",
    "rgbFrame = rgbCam.get().getCvFrame()\n",
    "leftFrame = leftCam.get().getCvFrame()\n",
    "rightFrame = rightCam.get().getCvFrame()\n",
    "ret, Thermalframe = thermalCam.read()\n",
    "stereoFrame = stereoCam.get().getCvFrame()\n",
    "\n",
    "print(\"rgbFrame:\", rgbFrame.shape)\n",
    "print(\"leftFrame:\", leftFrame.shape)\n",
    "print(\"rightFrame:\", rightFrame.shape)\n",
    "print(\"Thermalframe:\", Thermalframe.shape)\n",
    "print(\"stereoFrame:\", stereoFrame.shape)\n",
    "\n",
    "FPS = 10\n",
    "timeNow = str(datetime.now())[:-7].replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "print(timeNow)\n",
    "\n",
    "if RECORD:\n",
    "    base = f\"videos/{timeNow}\"\n",
    "    os.mkdir(base)\n",
    "    os.mkdir(f\"{base}/processed\")\n",
    "\n",
    "    rgbout = cv2.VideoWriter(f\"{base}/rgbout.mp4\", fourcc, FPS, (rgbFrame.shape[1], rgbFrame.shape[0]))\n",
    "    leftout = cv2.VideoWriter(f\"{base}/leftout.mp4\", fourcc, FPS, (leftFrame.shape[1], leftFrame.shape[0]), 0)\n",
    "    rightout = cv2.VideoWriter(f\"{base}/rightout.mp4\", fourcc, FPS, (rightFrame.shape[1], rightFrame.shape[0]), 0)\n",
    "    thermalout = cv2.VideoWriter(f\"{base}/thermalout.mp4\", fourcc, FPS, (Thermalframe.shape[1], Thermalframe.shape[0]), 0)\n",
    "    stereoout = cv2.VideoWriter(f\"{base}/stereoout.mp4\", fourcc, FPS, (stereoFrame.shape[1], stereoFrame.shape[0]), 0)\n",
    "\n",
    "print(stereoFrame.shape[1], stereoFrame.shape[0])\n",
    "\n",
    "#time.sleep(7)\n",
    "t0 = datetime.now()\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # Determine the initial frame time \n",
    "    initialFrameTime = datetime.now()\n",
    "          \n",
    "    rgbFrame = rgbCam.get().getCvFrame()\n",
    "    leftFrame = leftCam.get().getCvFrame()\n",
    "    rightFrame = rightCam.get().getCvFrame()\n",
    "    ret, Thermalframe = thermalCam.read()\n",
    "    stereoFrame = stereoCam.get().getFrame()\n",
    "    \n",
    "    if calibration_count % 5 == 0:\n",
    "        scales, offset = calibrate_images(images.copy(), seg_model, config.minimal_img)\n",
    "\n",
    "        if scales is not None and offset is not None:\n",
    "            if ten_scales[0] == [1, 1, 1]:\n",
    "                del ten_scales[0]\n",
    "                del ten_offsets[0]\n",
    "\n",
    "            ten_scales.append(scales)\n",
    "            ten_offsets.append(offset)\n",
    "\n",
    "        if len(ten_scales) > 30:\n",
    "            random_delete = int(np.random.rand() * 30)\n",
    "            \n",
    "            del ten_scales[random_delete]\n",
    "            del ten_offsets[random_delete]\n",
    "\n",
    "        scales, offset = filter_offsets_scales(ten_scales, ten_offsets)\n",
    "        scales = {\"RGB\": scales[0], \"Thermal\": scales[1], \"Depth\": scales[2]}\n",
    "        offset = {\"RGB\": offset[0], \"Thermal\": offset[1], \"Depth\": offset[2]}\n",
    "\n",
    "    # Convert stereo frame to grayscale for visualization\n",
    "    images[\"Depth\"] = cv2.cvtColor(images[\"Depth\"], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Modify images based on calibration settings\n",
    "    images[\"Unrelated\"] = superimpose_images(images.copy(), add_color=True)\n",
    "    images = modify_images(images.copy(), scales, offset, images[config.minimal_img].shape[0])\n",
    "\n",
    "    images[\"Related\"] = superimpose_images(images.copy(), add_color=True)\n",
    "\n",
    "    stereo_frame_mapped = cv2.normalize(images[\"Depth\"], None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\n",
    "    stereo_frame_mapped = cv2.equalizeHist(stereo_frame_mapped)\n",
    "    stereo_frame_mapped = cv2.applyColorMap(stereo_frame_mapped, cv2.COLORMAP_JET)\n",
    "    images[\"Color_Depth\"] = stereo_frame_mapped\n",
    "\n",
    "    # Create video files for processed output\n",
    "    if calibration_count == 0:\n",
    "        thermal_out = cv2.VideoWriter(f\"{config.processed_path}Thermal_sii.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "        stereo_out = cv2.VideoWriter(f\"{config.processed_path}Depth_sii.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]), 0)\n",
    "        rgb_out = cv2.VideoWriter(f\"{config.processed_path}RGB_sii.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "        related_sii_out = cv2.VideoWriter(f\"{config.processed_path}Related_SII.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "        unrelated_sii_out = cv2.VideoWriter(f\"{config.processed_path}Unrelated_SII.mp4\", config.fourcc, config.fps, (images[config.minimal_img].shape[:2][::-1]))\n",
    "\n",
    "    # Resize related and unrelated images\n",
    "    images[\"Related\"] = cv2.resize(images[\"Related\"], images[config.minimal_img].shape[:2][::-1])\n",
    "    images[\"Unrelated\"] = cv2.resize(images[\"Unrelated\"], images[config.minimal_img].shape[:2][::-1])\n",
    "\n",
    "    # Display images\n",
    "    for label in images:\n",
    "        cv2.imshow(label, images[label])\n",
    "\n",
    "    # Write frames to output video files\n",
    "    thermal_out.write(images[\"Thermal\"])\n",
    "    stereo_out.write(images[\"Depth\"])\n",
    "    rgb_out.write(images[\"RGB\"])\n",
    "    related_sii_out.write(images[\"Related\"])\n",
    "    unrelated_sii_out.write(images[\"Unrelated\"])\n",
    "\n",
    "    # Increment frame counters\n",
    "    calibration_count += 1\n",
    "    frame_count += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "print(\"\\nProcessing Ended. Saving videos...\")\n",
    "        \n",
    "# Release video files\n",
    "rgb_out.release()\n",
    "thermal_out.release()\n",
    "stereo_out.release()\n",
    "related_sii_out.release()\n",
    "unrelated_sii_out.release()\n",
    "\n",
    "print(\"Saving complete!\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
