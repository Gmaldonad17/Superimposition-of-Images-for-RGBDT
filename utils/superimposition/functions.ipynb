{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3937b506-fb11-4349-88b4-2bd3901ec715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks if two points are within a certain range of one another.\n",
    "def in_range(point1, point2, tolerance):\n",
    "    y_scale = 3\n",
    "\n",
    "    x_within_range = point1[0] - tolerance <= point2[0] <= point1[0] + tolerance\n",
    "    y_within_range = point1[1] - tolerance * y_scale <= point2[1] <= point1[1] + tolerance * y_scale\n",
    "\n",
    "    return x_within_range and y_within_range\n",
    "\n",
    "\n",
    "# This function calculates Intersection over Union (IoU) between two bounding boxes.\n",
    "def compute_iou(box_base, box_unknown):\n",
    "    x1, y1 = box_base[0] - box_base[2] / 2, box_base[1] - box_base[3] / 2\n",
    "    x2, y2 = box_base[0] + box_base[2] / 2, box_base[1] + box_base[3] / 2\n",
    "    x3, y3 = box_unknown[0] - box_unknown[2] / 2, box_unknown[1] - box_unknown[3] / 2\n",
    "    x4, y4 = box_unknown[0] + box_unknown[2] / 2, box_unknown[1] + box_unknown[3] / 2\n",
    "\n",
    "    # Calculate area of intersection\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    intersection_area = x_overlap * y_overlap\n",
    "\n",
    "    # Calculate area of union\n",
    "    box1_area = box_base[2] * box_base[3]\n",
    "    box2_area = box_unknown[2] * box_unknown[3]\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "# This function scales the input image by the specified scale factor.\n",
    "def scale_image(input_image, scale_factor):\n",
    "    width = input_image.shape[1]\n",
    "    height = input_image.shape[0]\n",
    "    output_image = cv2.resize(input_image, (int(width * scale_factor), int(height * scale_factor)))\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "# Squares images based on length does not interact with one dimension\n",
    "def square_images(input_images, resize_option=False):\n",
    "    output_images = []\n",
    "\n",
    "    for label in input_images:\n",
    "        img_shape = input_images[label].shape\n",
    "\n",
    "        # If the image is longer in width, reduce both sides equally to achieve desired size.\n",
    "        if img_shape[0] < img_shape[1]:  # Longer in width\n",
    "            reduction = int((img_shape[1] - img_shape[0]) / 2)\n",
    "\n",
    "            input_images[label] = input_images[label][:, reduction: img_shape[0] + reduction]\n",
    "\n",
    "        # If the image is taller in height, reduce both sides equally to achieve desired size.\n",
    "        if img_shape[0] > img_shape[1]:  # Taller in height\n",
    "            reduction = int((img_shape[0] - img_shape[1]) / 2)\n",
    "\n",
    "            input_images[label] = input_images[label][reduction: img_shape[1] + reduction]\n",
    "\n",
    "        # Resize all images to the same size if required\n",
    "        if type(resize_option) == int:\n",
    "            input_images[label] = cv2.resize(input_images[label], (resize_option, resize_option))\n",
    "\n",
    "    return input_images\n",
    "\n",
    "    \n",
    "# Scales normalized data to the image\n",
    "def scale_detections(detections, image):\n",
    "    \n",
    "    # Rescale detection coordinates based on the input image dimensions\n",
    "    detections[1::2] = [int(x * image.shape[1]) for x in detections[1::2]]  # X-Values\n",
    "    detections[2::2] = [int(y * image.shape[0]) for y in detections[2::2]]  # Y-Values\n",
    "\n",
    "    return detections\n",
    "\n",
    "# This function determines the most significant object in a set of images.\n",
    "def most_significant_object(detections):\n",
    "    machine_zero = 0.01\n",
    "\n",
    "    unique_classes = []\n",
    "\n",
    "    for i, detection in enumerate(detections):\n",
    "\n",
    "        if detection is None or detection.shape[0] == 0:\n",
    "            success = False\n",
    "            return success, detections\n",
    "\n",
    "        detection = np.array(detection)\n",
    "\n",
    "        # Remove objects touching the image border\n",
    "        border_mask = (detection[:, 1] - (detection[:, 3] / 2) >= machine_zero) \\\n",
    "                      & (1 - detection[:, 2] - (detection[:, 4] / 2) >= machine_zero) \\\n",
    "                      & (1 - detection[:, 1] - (detection[:, 3] / 2) >= machine_zero) \\\n",
    "                      & (detection[:, 2] - (detection[:, 4] / 2) >= machine_zero)\n",
    "\n",
    "        # Apply mask to remove objects\n",
    "        detections[i] = detection[border_mask]\n",
    "\n",
    "        # Find unique classes in the image\n",
    "        image_unique_classes = np.unique(np.array(detections[i][:, 0]))\n",
    "        unique_classes.extend([*image_unique_classes])\n",
    "\n",
    "    unique_classes = np.unique(unique_classes, return_counts=True)\n",
    "\n",
    "    # Find the first class present in all images\n",
    "    class_index = 0\n",
    "\n",
    "    if len(unique_classes[0]) == 0:\n",
    "        success = False\n",
    "        return success, detections\n",
    "\n",
    "    for i in range(len(unique_classes[0])):\n",
    "        class_index = i\n",
    "\n",
    "        if unique_classes[1][i] == 3:\n",
    "            break\n",
    "        if i == len(unique_classes[0]) - 1:\n",
    "            success = False\n",
    "            return success, detections\n",
    "\n",
    "    common_class = unique_classes[0][class_index]\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Create output array containing the largest object of each image, assumed to be the same object\n",
    "    for i, detection in enumerate(detections):\n",
    "        class_mask = (detection[:, 0] == common_class)\n",
    "        detection = detection[class_mask]\n",
    "\n",
    "        # Sort objects by size\n",
    "        detections[i] = np.array(sorted(detection, key=lambda det: det[-1] * det[-2], reverse=True))\n",
    "\n",
    "        # Select the largest object from each image\n",
    "        output.append(detections[i][0])\n",
    "\n",
    "    tolerance = 0.15\n",
    "\n",
    "    # Check if all objects are within range\n",
    "    iou_values = [compute_iou(output[0][1:], output[1][1:]),\n",
    "                  compute_iou(output[0][1:], output[2][1:]),\n",
    "                  compute_iou(output[1][1:], output[2][1:])]\n",
    "\n",
    "    min_iou = np.mean(iou_values)\n",
    "    tolerance = 0.2\n",
    "\n",
    "    success = in_range(output[0][1:3], output[1][1:3], tolerance) \\\n",
    "              & in_range(output[0][1:3], output[2][1:3], tolerance) \\\n",
    "              & in_range(output[1][1:3], output[2][1:3], tolerance)\n",
    "\n",
    "    if min_iou > tolerance and success:\n",
    "        success = True\n",
    "    else:\n",
    "        success = False\n",
    "\n",
    "    output = np.array(output)\n",
    "\n",
    "    # Return success flag and the output objects\n",
    "    return success, output\n",
    "\n",
    "\n",
    "def calibrate_images(images, model, minimal_img, depth_bias=1.0, view_relationship=True):\n",
    "    images_used = [\"RGB\", \"Thermal\", \"Left\"]\n",
    "\n",
    "    # Square incoming images to preserve ratio between all images\n",
    "    images = square_images(images)\n",
    "\n",
    "    multi_image_detections = []\n",
    "\n",
    "    # Gather detections for each image\n",
    "    for label in images_used:\n",
    "        detection = model.predict(source=images[label], classes=[0, 2], verbose=False, device=0)\n",
    "        detection = torch.cat((detection[0].boxes.cls.view(-1, 1), detection[0].boxes.xywhn), dim=1)\n",
    "        multi_image_detections.append(detection.cpu())\n",
    "\n",
    "    # Check if objects in images are identical\n",
    "    success, multi_image_detections = most_significant_object(multi_image_detections)\n",
    "\n",
    "    # If objects are not identical, return None\n",
    "    if not success:\n",
    "        return None, None\n",
    "\n",
    "    multi_image_detections = {\"RGB\": multi_image_detections[0], \"Thermal\": multi_image_detections[1], \"Left\": multi_image_detections[2]}\n",
    "\n",
    "    # Select the most important feature of the object, length or height\n",
    "    important_feature = {2.0: -2, 0.0: -1}\n",
    "    important_feature = important_feature[multi_image_detections[minimal_img][0]]\n",
    "\n",
    "    # Find the smallest object, assume this camera holds the most information\n",
    "    min_size = multi_image_detections[minimal_img][important_feature]\n",
    "    min_idx = minimal_img\n",
    "\n",
    "    # Scale detections of minimal image since it will not change\n",
    "    multi_image_detections[minimal_img] = scale_detections(multi_image_detections[minimal_img], images[minimal_img])\n",
    "\n",
    "    scales = []\n",
    "    offsets = []\n",
    "\n",
    "    # Calculate the relationship of each image in relation to the smallest\n",
    "    for label in images_used:\n",
    "\n",
    "        if label == minimal_img:\n",
    "            # If the minimal image is encountered, set relationship to None\n",
    "            scales.append(1)\n",
    "            offsets.append([0, 0, 0, 0])\n",
    "            continue\n",
    "\n",
    "        # Calculate scale based on difference of feature size\n",
    "        scale = (min_size * images[minimal_img].shape[0]) / (multi_image_detections[label][important_feature] * images[label].shape[0])\n",
    "\n",
    "        if label == \"Left\":\n",
    "            scale *= depth_bias\n",
    "\n",
    "        # Resize images based on scale\n",
    "        images[label] = scale_image(images[label].copy(), scale)\n",
    "\n",
    "        # Scale detections after resizing\n",
    "        single_image_detection = scale_detections(multi_image_detections[label], images[label])\n",
    "\n",
    "        # Calculate difference in resolution\n",
    "        resolution_diff_x = images[minimal_img].shape[1] - images[label].shape[1]\n",
    "        resolution_diff_y = images[minimal_img].shape[0] - images[label].shape[0]\n",
    "\n",
    "        # Compare offset of the object compared to minimal image\n",
    "        offset_x = multi_image_detections[minimal_img][1] - single_image_detection[1]\n",
    "        offset_y = multi_image_detections[minimal_img][2] - single_image_detection[2]\n",
    "\n",
    "        # Calculate top, bottom, left, and right offsets\n",
    "        top = int(offset_y)\n",
    "        bottom = int(resolution_diff_y - offset_y)\n",
    "        left = int(offset_x)\n",
    "        right = int(resolution_diff_x - offset_x)\n",
    "\n",
    "        # Create offset and scale values, this is the relationship between the images\n",
    "        offsets.append([top, bottom, left, right])\n",
    "        \n",
    "            \n",
    "        scales.append(scale)\n",
    "\n",
    "        # Visualize the relationship if requested\n",
    "        if view_relationship:\n",
    "            relationship_img = images[label].copy()\n",
    "            x = int(single_image_detection[1])\n",
    "            y = int(single_image_detection[2])\n",
    "            \n",
    "            relationship_img = cv2.line(relationship_img, (x, y), (x + left, y), (0, 255, 0), 2)\n",
    "            relationship_img = cv2.line(relationship_img, (x, y), (x, y + top), (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"cali_\" + label, relationship_img)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "    return scales, offsets\n",
    "\n",
    "\n",
    "# Adjusts images based on the relationship information to match the minimal image\n",
    "def modify_images(images, scales, offsets, min_image_size):\n",
    "    images_used = [\"RGB\", \"Thermal\", \"Depth\"]\n",
    "\n",
    "    # Modify images to match the minimal image\n",
    "    for label in images_used:\n",
    "\n",
    "        if scales[label] == 1:\n",
    "            images[label] = square_images({label: images[label]})[label]\n",
    "            continue\n",
    "\n",
    "        # Scale images\n",
    "        images[label] = scale_image(images[label], scales[label])\n",
    "\n",
    "        top, bottom, left, right = offsets[label]\n",
    "\n",
    "        # Calculate padding for the square image\n",
    "        padding = int((images[label].shape[1] - images[label].shape[0]) / 2)\n",
    "\n",
    "        # Calculate left padding taking into account the offset\n",
    "        left_padding = padding - left\n",
    "\n",
    "        # Crop the image horizontally\n",
    "        images[label] = images[label][:, left_padding: left_padding + min_image_size]\n",
    "\n",
    "        # Adjust right padding if necessary\n",
    "        right = int(min_image_size - images[label].shape[1])\n",
    "\n",
    "        # Adjust top and bottom padding\n",
    "        if top < 0:\n",
    "            images[label] = images[label][-top:min_image_size - top]\n",
    "            top = 0\n",
    "        else:\n",
    "            images[label] = images[label][:min_image_size - top]\n",
    "\n",
    "        bottom = int(min_image_size - images[label].shape[0] - top)\n",
    "\n",
    "        # Add borders to image to fit, using abs for error prevention\n",
    "        images[label] = cv2.copyMakeBorder(images[label], abs(top), abs(bottom), 0, abs(right), cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "# Applies masks to the images to create the SII\n",
    "def apply_mask(images, masks, main_img):\n",
    "\n",
    "    # Copy the main image to avoid modifying the original\n",
    "    super_imposed_image = images[main_img].copy()\n",
    "\n",
    "    master_mask = []\n",
    "\n",
    "    # Combine all masks\n",
    "    if masks is not None:\n",
    "        for m in masks:\n",
    "\n",
    "            m = np.array(m)\n",
    "\n",
    "            # Scale mask to match image size\n",
    "            m = cv2.resize(m, super_imposed_image.shape[:2][::-1])\n",
    "\n",
    "            if len(master_mask) == 0:\n",
    "                master_mask = m\n",
    "            else:\n",
    "                master_mask += m\n",
    "\n",
    "    else:\n",
    "        return super_imposed_image\n",
    "\n",
    "    # Invert master_mask to remove objects from the image\n",
    "    master_mask = 1 - master_mask\n",
    "\n",
    "    # Convert to bool to apply to images\n",
    "    master_mask = master_mask.astype(bool)\n",
    "\n",
    "    # Create masked copies of the thermal and depth images\n",
    "    thermal_masked = images[\"Thermal\"].copy()\n",
    "    stereo_masked = images[\"Color_Depth\"].copy()\n",
    "\n",
    "    # Resize images if necessary\n",
    "    if thermal_masked.shape != master_mask.shape:\n",
    "        thermal_masked = cv2.resize(thermal_masked, master_mask.shape[:2][::-1])\n",
    "        stereo_masked = cv2.resize(stereo_masked, master_mask.shape[:2][::-1])\n",
    "        super_imposed_image = cv2.resize(super_imposed_image, master_mask.shape[:3][::-1])\n",
    "\n",
    "    # Set pixels not related to objects to zero\n",
    "    thermal_masked[master_mask] = 0\n",
    "    stereo_masked[master_mask] = 0\n",
    "\n",
    "    # Display the images to check if the mask is working correctly\n",
    "    cv2.imshow(\"thermalMasked\", thermal_masked)\n",
    "    cv2.imshow(\"stereoMasked\", stereo_masked)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # Apply the depth mask to the super_imposed image\n",
    "    mask = stereo_masked.astype(bool)\n",
    "    super_imposed_image[mask] = cv2.addWeighted(super_imposed_image, 0.70, stereo_masked, 0.30, 0)[mask]\n",
    "    \n",
    "    # Apply the thermal mask to the super_imposed image\n",
    "    mask = thermal_masked.astype(bool)\n",
    "    super_imposed_image[mask] = cv2.addWeighted(super_imposed_image, 0.65, thermal_masked, 0.35, 0)[mask]\n",
    "\n",
    "    # Return the final super_imposed image\n",
    "    return super_imposed_image\n",
    "    \n",
    "    \n",
    "def superimpose_images(images, resize=512, add_color=False):\n",
    "    # Resize images to the specified size and make them square\n",
    "    images = square_images(images, resize)\n",
    "\n",
    "    if add_color:\n",
    "        # Normalize the depth image, enhance contrast and apply color map\n",
    "        images[\"Depth\"] = cv2.normalize(images[\"Depth\"], None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\n",
    "        images[\"Depth\"] = cv2.equalizeHist(images[\"Depth\"])\n",
    "        images[\"Depth\"] = cv2.applyColorMap(images[\"Depth\"], cv2.COLORMAP_JET)\n",
    "\n",
    "    # Blend the RGB and depth images using weights, then blend the result with the thermal image\n",
    "    superimposed_image = cv2.addWeighted(images[\"RGB\"], 0.70, images[\"Depth\"], 0.30, 0)\n",
    "    superimposed_image = cv2.addWeighted(superimposed_image, 0.65, images[\"Thermal\"], 0.35, 0)\n",
    "\n",
    "    return superimposed_image\n",
    "\n",
    "def filter_offsets_scales(TenScales, TenOffsets, scale_filter=np.median, offset_filter=np.median):\n",
    "    # Filter scales by applying the scale_filter function to each component of the TenScales list\n",
    "    filtered_scales = [scale_filter([i[0] for i in TenScales]),\n",
    "                       scale_filter([i[1] for i in TenScales]),\n",
    "                       scale_filter([i[2] for i in TenScales])]\n",
    "    \n",
    "    # Filter offsets by applying the offset_filter function to each component of the TenOffsets list\n",
    "    filtered_offsets = []\n",
    "    for i in range(3):\n",
    "        # Extract the i-th component of each offset in TenOffsets and apply offset_filter to get the filtered value\n",
    "        row = [offset_filter([j[i][k] for j in TenOffsets]) for k in range(4)]\n",
    "        # Convert the float values to integers\n",
    "        row = [int(x) for x in row]\n",
    "        # Add the filtered row to the filtered_offsets list\n",
    "        filtered_offsets.append(row)\n",
    "\n",
    "    # Return the filtered scales and offsets\n",
    "    return filtered_scales, filtered_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc52d9-bfb7-4f4e-b106-aa6832224127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
