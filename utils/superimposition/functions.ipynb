{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3937b506-fb11-4349-88b4-2bd3901ec715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if two points are within a certain range of one another\n",
    "def inRange(p1, p2, tol): # p1 newpoint p2 currentpoint\n",
    "    yscale = 3\n",
    "\n",
    "    xbool = p1[0]-tol <= p2[0] <= p1[0]+tol\n",
    "    ybool = p1[1]-tol*yscale <= p2[1] <= p1[1]+tol*yscale\n",
    "\n",
    "    return xbool and ybool\n",
    "\n",
    "def IOU(base, unk):\n",
    "        x1, y1 = base[0]-base[2]/2, base[1]-base[3]/2\n",
    "        x2, y2 = base[0]+base[2]/2, base[1]+base[3]/2\n",
    "        x3, y3 = unk[0]-unk[2]/2, unk[1]-unk[3]/2\n",
    "        x4, y4 = unk[0]+unk[2]/2, unk[1]+unk[3]/2\n",
    "\n",
    "        # Calculate area of intersection\n",
    "        x_overlap = max(0, min(x2,x4) - max(x1,x3))\n",
    "        y_overlap = max(0, min(y2,y4) - max(y1,y3))\n",
    "        intersection_area = x_overlap * y_overlap\n",
    "\n",
    "        # Calculate area of union\n",
    "        box1_area = base[2] * base[3]\n",
    "        box2_area = unk[2] * unk[3]\n",
    "        union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "        # Calculate IoU\n",
    "        iou = intersection_area / union_area\n",
    "        \n",
    "        return iou\n",
    "\n",
    "def scale_image(image, scale):\n",
    "    x = image.shape[1]\n",
    "    y = image.shape[0]\n",
    "    image = cv2.resize(image, ( int(x*scale), int(y*scale) ))\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "# Squares images based on length does not interact with one dimension\n",
    "def square_photos(images, resize=False):\n",
    "    \n",
    "    newImgs = []\n",
    "    \n",
    "    for label in images:\n",
    "        shape = images[label].shape\n",
    "\n",
    "        # If long then reduce both sides equally until research desired size\n",
    "        if shape[0] < shape[1]: # Long\n",
    "            r = int( (shape[1] - shape[0]) / 2 ) \n",
    "\n",
    "            images[label] = images[label][:,r : shape[0] + r] \n",
    "            \n",
    "        # If Tall then reduce both sides equally until research desired size\n",
    "        if shape[0] > shape[1]: # Tall \n",
    "            r = int( (shape[0] - shape[1]) / 2 )\n",
    "\n",
    "            images[label] = images[label][r : shape[1] + r]\n",
    "        \n",
    "        # Resize all images to the same size if required\n",
    "        if type(resize) == int:\n",
    "            images[label] = cv2.resize(images[label], (resize, resize) )\n",
    "    \n",
    "    return images\n",
    "\n",
    "    \n",
    "# Scales normalized data to the image\n",
    "def scale_detections(det, img):\n",
    "    \n",
    "    # Remakes array with resized objects \n",
    "    det[1::2] = [ int(x * img.shape[1]) for x in det[1::2] ] # X-Values\n",
    "    det[2::2] = [ int(y * img.shape[0]) for y in det[2::2] ] # Y-Values\n",
    "    \n",
    "    return det\n",
    "\n",
    "# Determines the most significate object in an image\n",
    "def mostSigObject(detects):\n",
    "    \n",
    "    zero = 0.01 # Machine zero\n",
    "    \n",
    "    unique = []\n",
    "    \n",
    "    for i, det in enumerate(detects):\n",
    "        \n",
    "        if det == None or det.shape[0] == 0:\n",
    "            flag = False\n",
    "\n",
    "            # If no image has the same classes then return false\n",
    "            # print(\"No Valid Detections\")\n",
    "            return flag, detects\n",
    "\n",
    "        det = np.array(det)\n",
    "        \n",
    "        # Delete Objects which border the image\n",
    "        rangeMask = (det[:,1] - (det[:,3]/2) >= zero) \\\n",
    "                    & (1 - det[:,2] - (det[:,4]/2) >= zero) \\\n",
    "                    & (1 - det[:,1] - (det[:,3]/2) >= zero) \\\n",
    "                    & (det[:,2] - (det[:,4]/2) >= zero)\n",
    "        \n",
    "        # Overlays mask to remove objects\n",
    "        detects[i] = det[rangeMask]\n",
    "        \n",
    "        # Find unique classes in image\n",
    "        uniqueClasses = np.unique(np.array(detects[i][:,0]))\n",
    "        unique.extend([*uniqueClasses])\n",
    "        \n",
    "    unique = np.unique(unique, return_counts=True)# \n",
    "    # unique[0] = unique[0][::-1] # If decided to reverse the classes\n",
    "    \n",
    "    # The index of which value to use\n",
    "    index = 0\n",
    "    \n",
    "    if len(unique[0]) == 0:\n",
    "        flag = False\n",
    "        \n",
    "        # print(\"Objects detected but all Invalid\")\n",
    "        return flag, detects\n",
    "    \n",
    "    # Loops finds the first class with the same number of objects as images\n",
    "    for i in range(len(unique[0])): ### Maybe instead of the first calculate who has higher confidence \n",
    "        index = i\n",
    "        \n",
    "        if unique[1][i] == 3:\n",
    "            break\n",
    "        if i == len(unique[0])-1:\n",
    "            flag = False\n",
    "            \n",
    "            # If no image has the same classes then return false\n",
    "            # print(\"All images do not have same class\")\n",
    "            return flag, detects\n",
    "        \n",
    "    # Object class which is in all images\n",
    "    comparedClass = unique[0][index]\n",
    "    # print(\"comparedClass: \", comparedClass)\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    # Create output array of single objects assumed to be same object\n",
    "    for i, det in enumerate(detects):\n",
    "        classMask = (det[:,0] == comparedClass)\n",
    "        det = det[classMask]\n",
    "        \n",
    "        # Sorts objects by size \n",
    "        detects[i] = np.array(sorted(det, key=lambda det : det[-1]*det[-2], reverse=True))\n",
    "        \n",
    "        # Grabs the largest object from each image\n",
    "        output.append(detects[i][0])\n",
    "    \n",
    "    # print(\"Largest Objects selected \\n\", np.array(output))\n",
    "    \n",
    "    tol = 0.15 # Tolerance range an object can be within to be the same\n",
    "    \n",
    "    # Check if all objects are within range\n",
    "    # print(output)\n",
    "    \n",
    "    iou = [IOU(output[0][1:], output[1][1:]), \n",
    "               IOU(output[0][1:], output[2][1:]),\n",
    "               IOU(output[1][1:], output[2][1:])]\n",
    "    \n",
    "    minIOU = np.mean(iou)\n",
    "    tol = 0.2\n",
    "    \n",
    "    flag = inRange(output[0][1:3], output[1][1:3], tol) \\\n",
    "    & inRange(output[0][1:3], output[2][1:3], tol) \\\n",
    "    & inRange(output[1][1:3], output[2][1:3], tol)\n",
    "    \n",
    "    if minIOU > tol and flag:\n",
    "        flag = True\n",
    "        \n",
    "    else:\n",
    "        # print(\"Objects are not within Range\")\n",
    "        flag = False\n",
    "    \n",
    "    output = np.array(output) \n",
    "    \n",
    "    # Return if objects are valid and output those objects\n",
    "    return flag, output\n",
    "\n",
    "\n",
    "# Calculates relationship of all images and records relationship\n",
    "def calibration(images, model, minimalImg, view_relationship=True):\n",
    "    \n",
    "    imagesUsed = [\"RGB\", \"Thermal\", \"Left\"]\n",
    "    \n",
    "    # Square incomming images to preserve ratio between all images\n",
    "    images = square_photos(images)\n",
    "    \n",
    "    multiImageDetections = []\n",
    "    \n",
    "    # Goes through each image to gather detections\n",
    "    for label in imagesUsed:\n",
    "        \n",
    "        det = model.predict(source=images[label], classes=[0,2], verbose=False, device=0)\n",
    "        det = torch.cat((det[0].boxes.cls.view(-1,1), det[0].boxes.xywhn), dim=1)\n",
    "        \n",
    "        multiImageDetections.append(det.cpu())\n",
    "        \n",
    "    # Returns if objects are identical or not\n",
    "    flag, multiImageDetections = mostSigObject(multiImageDetections)\n",
    "    \n",
    "    \n",
    "    # If not identical error out\n",
    "    if not flag:\n",
    "        return None, None\n",
    "    \n",
    "    multiImageDetections = {\"RGB\": multiImageDetections[0], \"Thermal\": multiImageDetections[1], \"Left\": multiImageDetections[2]}\n",
    "    \n",
    "    \n",
    "    # Selects most important feature of object, length or height\n",
    "    item = {2.0 : -2, 0.0 : -1}\n",
    "    item = item[multiImageDetections[minimalImg][0]]\n",
    "    \n",
    "    \n",
    "    # Finds smallest object, assumes this camera holds most infomation\n",
    "    min_size = multiImageDetections[minimalImg][item]\n",
    "    # min_idx = np.argmin(multiImageDetections[:,item])\n",
    "    # min_size = images[minimalImg].shape[0]\n",
    "    min_idx = minimalImg\n",
    "    \n",
    "    # Scale detections of minimal image since it will not change\n",
    "    multiImageDetections[minimalImg] = scale_detections( multiImageDetections[minimalImg], images[minimalImg] )\n",
    "    \n",
    "    scales = []\n",
    "    offset = []\n",
    "    \n",
    "    # Go through each photo and calculate the relationship of each photo in relation to the smallest\n",
    "    for label in imagesUsed:\n",
    "        \n",
    "        # If smallest image than set relationship to None\n",
    "        if label == minimalImg:\n",
    "            \n",
    "            # If the minimal image is encountered then relationship is change nothing\n",
    "            scales.append(1)\n",
    "            offset.append([0,0,0,0])\n",
    "            continue\n",
    "        \n",
    "        # Calculate scale based on difference of item size\n",
    "        # print(multiImageDetections[label])\n",
    "        scale = (min_size * images[minimalImg].shape[0]) / (multiImageDetections[label][item] * images[label].shape[0])\n",
    "        \n",
    "        # Resize images based on scale\n",
    "        images[label] = scale_image(images[label].copy(), scale)\n",
    "        \n",
    "        # After resize scale detections\n",
    "        singleImageDetection = scale_detections(multiImageDetections[label], images[label])\n",
    "        \n",
    "        # What is the difference in resolution \n",
    "        resolutionDiff_x = images[minimalImg].shape[1] - images[label].shape[1] # All space for x\n",
    "        resolutionDiff_y = images[minimalImg].shape[0] - images[label].shape[0] # All space for y\n",
    "        \n",
    "        # Compare how offset an object is compared to minimal image\n",
    "        offset_x = multiImageDetections[minimalImg][1] - singleImageDetection[1]\n",
    "        offset_y = multiImageDetections[minimalImg][2] - singleImageDetection[2]\n",
    "        \n",
    "        # Use left and top to move objects into place and bottom and right to simply make images same ints required\n",
    "        top = int(offset_y)\n",
    "        bottom = int(resolutionDiff_y - offset_y)\n",
    "        left = int(offset_x)\n",
    "        right = int(resolutionDiff_x - offset_x)\n",
    "        \n",
    "        # Create offset and scale values, this is the relationship between the images\n",
    "        offset.append([top, bottom, left, right])\n",
    "        scales.append(scale)\n",
    "    \n",
    "        # View in image how object must be translated to match minimal image\n",
    "        if view_relationship:\n",
    "            \n",
    "            relationshipImg = images[label].copy()\n",
    "            x = int(singleImageDetection[1])\n",
    "            y = int(singleImageDetection[2])\n",
    "            \n",
    "            relationshipImg = cv2.line(relationshipImg, (x, y), (x + left, y), (0,255,0), 2)\n",
    "            relationshipImg = cv2.line(relationshipImg, (x, y), (x, y + top), (0,0,255), 2)\n",
    "            \n",
    "            cv2.imshow(\"cali_\"+label, relationshipImg)\n",
    "            cv2.waitKey(1)\n",
    "                \n",
    "    \n",
    "    # minImageSize = images[minimalImg].shape[0]\n",
    "    \n",
    "    return scales, offset\n",
    "\n",
    "\n",
    "### Still have to figure out negative tops, and rights\n",
    "### Getting good idea about fixing it, fuck the bottom and right, focus on left and top, then just go the nessassary amount\n",
    "# Adds relationship infomation to images to make same as minimal image\n",
    "def modify_images(images, scales, offsets, minImageSize):\n",
    "    imagesUsed = [\"RGB\", \"Thermal\", \"Depth\"]\n",
    "    \n",
    "    # Alter images to match minimal image\n",
    "    for label in imagesUsed:\n",
    "        \n",
    "        if scales[label] == 1:\n",
    "            images[label] = square_photos({label: images[label]})[label]\n",
    "            continue\n",
    "        \n",
    "        # Scale Images\n",
    "        images[label] = scale_image(images[label], scales[label])\n",
    "        \n",
    "        top, bottom, left, right = offset[label]\n",
    "        \n",
    "        # Used to orient everything from square image\n",
    "        p = int( (images[label].shape[1] - images[label].shape[0]) / 2 ) ### Not sure what to name this variable\n",
    "        \n",
    "        # Supports negative and positive left values\n",
    "        l = p - left \n",
    "\n",
    "        # Removes unnessassary pixel values \n",
    "        images[label] = images[label][:, l: l+minImageSize]\n",
    "        \n",
    "        # If there is still space requied, then fill it with black space\n",
    "        right = int(minImageSize - images[label].shape[1])\n",
    "        \n",
    "        if top < 0:\n",
    "            images[label] = images[label][-top:minImageSize-top]\n",
    "            top = 0\n",
    "        else:\n",
    "            images[label] = images[label][:minImageSize-top]\n",
    "            \n",
    "            \n",
    "        bottom = int(minImageSize - images[label].shape[0] - top)\n",
    "        \n",
    "        # Add borders to image to fit ### abs is just error preventation since I havent done negatives for some of them yet\n",
    "        images[label] = cv2.copyMakeBorder(images[label], abs(top), abs(bottom), 0, abs(right), cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        \n",
    "    return images\n",
    "\n",
    "\n",
    "# Mask the images to create the SII\n",
    "def apply_mask(images, masks, mainImg):\n",
    "    \n",
    "    # Copy image as to not affect main image\n",
    "    superImposedImage = images[mainImg].copy()\n",
    "    \n",
    "    masterMask = []\n",
    "    \n",
    "    # Add all mask together\n",
    "    if masks != None:\n",
    "        for m in masks:\n",
    "            \n",
    "            m = np.array(m)\n",
    "\n",
    "            # Scale Mask to Images\n",
    "            m = cv2.resize(m, superImposedImage.shape[:2][::-1])\n",
    "\n",
    "            if len(masterMask) == 0:\n",
    "                masterMask = m\n",
    "            else:\n",
    "                masterMask += m\n",
    "    \n",
    "    else:\n",
    "        return superImposedImage\n",
    "    \n",
    "    # Invert masterMask because this will delete objects \n",
    "    masterMask = 1 - masterMask\n",
    "    \n",
    "    # Change to bool to effect images\n",
    "    masterMask = masterMask.astype(bool)\n",
    "    \n",
    "    # Set pixels not related to objects to zero\n",
    "    thermalMasked = images[\"Thermal\"].copy() # Images must be copied for or else its gonna mess with original images\n",
    "    stereoMasked = images[\"Color_Depth\"].copy() \n",
    "    # stereoMasked = cv2.cvtColor(stereoMasked, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    \n",
    "    if thermalMasked.shape != masterMask.shape:\n",
    "        thermalMasked = cv2.resize(thermalMasked, masterMask.shape[:2][::-1]) \n",
    "        stereoMasked = cv2.resize(stereoMasked, masterMask.shape[:2][::-1]) \n",
    "        superImposedImage = cv2.resize(superImposedImage, masterMask.shape[:3][::-1]) \n",
    "    \n",
    "    # Set pixels not related to objects to zero\n",
    "    thermalMasked[masterMask] = 0\n",
    "    stereoMasked[masterMask] = 0\n",
    "    \n",
    "    \n",
    "    # Display the images to see if mask is working correctly\n",
    "    cv2.imshow(\"thermalMasked\", thermalMasked)\n",
    "    cv2.imshow(\"stereoMasked\", stereoMasked)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # Mask non-required pixels \n",
    "    mask = stereoMasked.astype(bool)\n",
    "    \n",
    "    # Add thermal pixel infomation\n",
    "    superImposedImage[mask] = cv2.addWeighted(superImposedImage, 0.70, stereoMasked, 0.30, 0)[mask]\n",
    "    \n",
    "    # Mask non-required pixels \n",
    "    mask = thermalMasked.astype(bool)\n",
    "    \n",
    "    # Add thermal pixel infomation\n",
    "    superImposedImage[mask] = cv2.addWeighted(superImposedImage, 0.65, thermalMasked, 0.35, 0)[mask]\n",
    "    \n",
    "    # Finally return image \n",
    "    return superImposedImage\n",
    "    \n",
    "    \n",
    "# A simple overlay function for showing superimposition without adding relationship\n",
    "def superimpose_images(images, resize=512, addColor=False):\n",
    "    \n",
    "    images = square_photos(images, resize)\n",
    "    \n",
    "    if addColor:\n",
    "        images[\"Depth\"] = cv2.normalize(images[\"Depth\"], None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\n",
    "        images[\"Depth\"] = cv2.equalizeHist(images[\"Depth\"])\n",
    "        images[\"Depth\"] = cv2.applyColorMap(images[\"Depth\"], cv2.COLORMAP_JET)\n",
    "    \n",
    "    superImposedImage = cv2.addWeighted(images[\"RGB\"], 0.70, images[\"Depth\"], 0.30, 0)\n",
    "    superImposedImage = cv2.addWeighted(superImposedImage, 0.65, images[\"Thermal\"], 0.35, 0)\n",
    "    \n",
    "    return superImposedImage\n",
    "\n",
    "def filter_offsets_scales(TenScales, TenOffsets, scale_filter=np.median, offset_filter=np.median):\n",
    "    \n",
    "    filteredScales = [ scale_filter([i[0] for i in TenScales]), scale_filter([i[1] for i in TenScales]),  scale_filter([i[2] for i in TenScales]) ]\n",
    "    \n",
    "    filteredOffset = [[],[],[]]\n",
    "    filteredOffset[0] = [int(offset_filter([i[0][0] for i in TenOffsets])), int(offset_filter([i[0][1] for i in TenOffsets])), int(offset_filter([i[0][2] for i in TenOffsets])), int(offset_filter([i[0][3] for i in TenOffsets]))]\n",
    "    filteredOffset[1] = [int(offset_filter([i[1][0] for i in TenOffsets])), int(offset_filter([i[1][1] for i in TenOffsets])), int(offset_filter([i[1][2] for i in TenOffsets])), int(offset_filter([i[1][3] for i in TenOffsets]))]\n",
    "    filteredOffset[2] = [int(offset_filter([i[2][0] for i in TenOffsets])), int(offset_filter([i[2][1] for i in TenOffsets])), int(offset_filter([i[2][2] for i in TenOffsets])), int(offset_filter([i[2][3] for i in TenOffsets]))]\n",
    "    \n",
    "    return filteredScales, filteredOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc52d9-bfb7-4f4e-b106-aa6832224127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
