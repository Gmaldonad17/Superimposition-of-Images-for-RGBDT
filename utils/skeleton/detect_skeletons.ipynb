{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "872ae76d-22d5-4159-87bb-3c8218993010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_skeleton(pose_model, img, detections):\n",
    "    \n",
    "#     detections = [i for i in detections if i[0] == 0]\n",
    "\n",
    "#     for i, _ in enumerate(detections):\n",
    "#         detections[i] = scale_detections(detections[i], img)\n",
    "#         detections[i][1] = int(detections[i][1]-detections[i][3]/2)\n",
    "#         detections[i][2] = int(detections[i][2]-detections[i][4]/2)\n",
    "\n",
    "#     detections = [dict(bbox=x[1:]) for x in list(detections)]\n",
    "    \n",
    "    pose = inference_top_down_pose_model(pose_model, img, detections, format='xyxy')[0]\n",
    "    \n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b845363-5dd5-4ab2-b0f2-30c9593f50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_detections(det, img):\n",
    "    \n",
    "#     # Remakes array with resized objects \n",
    "#     det[1::2] = [ int(x * img.shape[1]) for x in det[1::2] ] # X-Values\n",
    "#     det[2::2] = [ int(y * img.shape[0]) for y in det[2::2] ] # Y-Values\n",
    "    \n",
    "#     return det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15136b8a-1173-453c-9f09-7e3183df2dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "yolov7-tiny summary: 200 layers, 6219709 parameters, 6219709 gradients\n",
      "C:\\Users\\gmald\\anaconda3\\envs\\senior\\lib\\site-packages\\torch\\nn\\modules\\module.py:675: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:485.)\n",
      "  if param.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import torch\n",
    "\n",
    "# from mmpose.apis import inference_top_down_pose_model, init_pose_model, vis_pose_result\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# pose_config = \"demo/hrnet_w32_coco_256x192.py\"\n",
    "# pose_checkpoint = \"https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\"\n",
    "# img = cv2.imread(\"../../photos/streetTest.png\")\n",
    "\n",
    "\n",
    "# %run ../segmentation/detect.ipynb\n",
    "# BB_model = loadModel(\"../segmentation/yolov7-tiny.pt\")\n",
    "# det = detectObjects(img.copy(), BB_model, conf_thres=0.80, nameAdd=\"img\", maskModel=False, view_img=True)\n",
    "\n",
    "# img = cv2.resize(img, (512, 512))\n",
    "# pose_model = init_pose_model(pose_config, pose_checkpoint, device)\n",
    "    \n",
    "# pose = detect_skeleton(pose_model, img, det)\n",
    "\n",
    "# newImg = vis_pose_result(pose_model, img, pose)\n",
    "\n",
    "# cv2.imshow(\"skel\", newImg)\n",
    "# cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c045d58d-6fdf-4953-b7cb-3cf7aaa369c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555e3a5-c998-45be-8951-ee193355f0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36e5a1-20e3-4bfe-bcbc-c16ab1b122fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
